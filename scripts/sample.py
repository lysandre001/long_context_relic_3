#!/usr/bin/env python3
"""
å‡è¡¡æŠ½æ ·è„šæœ¬ï¼šä»CSVä¸­éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„æ•°æ®ï¼Œä¿è¯æŒ‡å®šåˆ—çš„å„ä¸ªç»´åº¦å–æ•°å‡è¡¡ã€‚

ç¤ºä¾‹:
    python /Users/yilin/project/251210__æ‹‰ä¸æ–‡benchmark/long_context_relic_3/scripts/sample.py data/Aeneid_commentary_Conington.csv -n 50 -c book_title -o Aeneid_commentary_Conington_sampled50.csv

å‚æ•°:
    input.csv       è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
    -n, --num       è¦æŠ½å–çš„æ€»æ•°é‡
    -c, --column    ç”¨äºå‡è¡¡çš„åˆ—å
    -o, --output    è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤ä¸º input_sampled.csv)
    --seed          éšæœºç§å­ (å¯é€‰ï¼Œç”¨äºå¤ç°ç»“æœ)
    --show-stats    æ˜¾ç¤ºæŠ½æ ·ç»Ÿè®¡ä¿¡æ¯
"""

import argparse
import pandas as pd
import random
from pathlib import Path


def balanced_sample(df: pd.DataFrame, column: str, total_num: int, seed: int = None) -> pd.DataFrame:
    """
    ä»DataFrameä¸­è¿›è¡Œå‡è¡¡æŠ½æ ·ã€‚
    
    Args:
        df: è¾“å…¥çš„DataFrame
        column: ç”¨äºå‡è¡¡çš„åˆ—å
        total_num: è¦æŠ½å–çš„æ€»æ•°é‡
        seed: éšæœºç§å­
        
    Returns:
        æŠ½æ ·åçš„DataFrame
    """
    if seed is not None:
        random.seed(seed)
    
    # è·å–è¯¥åˆ—çš„æ‰€æœ‰å”¯ä¸€å€¼
    unique_values = df[column].unique()
    num_categories = len(unique_values)
    
    print(f"\nğŸ“Š åˆ— '{column}' å…±æœ‰ {num_categories} ä¸ªä¸åŒçš„å€¼:")
    value_counts = df[column].value_counts()
    for val in unique_values:
        print(f"   - {val}: {value_counts[val]} æ¡")
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«åº”è¯¥æŠ½å–çš„æ•°é‡
    base_per_category = total_num // num_categories
    remainder = total_num % num_categories
    
    print(f"\nğŸ¯ ç›®æ ‡æŠ½å–æ€»æ•°: {total_num}")
    print(f"   æ¯ä¸ªç±»åˆ«åŸºç¡€æŠ½å–æ•°: {base_per_category}")
    if remainder > 0:
        print(f"   é¢å¤–åˆ†é…ç»™å‰ {remainder} ä¸ªç±»åˆ«å„ 1 æ¡")
    
    sampled_dfs = []
    stats = {}
    
    # æ‰“ä¹±ç±»åˆ«é¡ºåºï¼Œè®©ä½™æ•°çš„åˆ†é…ä¹Ÿæ˜¯éšæœºçš„
    shuffled_values = list(unique_values)
    random.shuffle(shuffled_values)
    
    for i, value in enumerate(shuffled_values):
        # ç¡®å®šè¿™ä¸ªç±»åˆ«éœ€è¦æŠ½å–çš„æ•°é‡
        num_to_sample = base_per_category + (1 if i < remainder else 0)
        
        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰æ•°æ®
        category_df = df[df[column] == value]
        available = len(category_df)
        
        # å¦‚æœè¯¥ç±»åˆ«æ•°æ®ä¸è¶³ï¼Œå°±å–å…¨éƒ¨
        actual_sample = min(num_to_sample, available)
        
        if actual_sample < num_to_sample:
            print(f"   âš ï¸  ç±»åˆ« '{value}' åªæœ‰ {available} æ¡æ•°æ®ï¼Œä¸è¶³ {num_to_sample} æ¡")
        
        # éšæœºæŠ½æ ·
        sampled = category_df.sample(n=actual_sample, random_state=seed)
        sampled_dfs.append(sampled)
        stats[value] = actual_sample
    
    # åˆå¹¶æ‰€æœ‰æŠ½æ ·ç»“æœ
    result = pd.concat(sampled_dfs, ignore_index=True)
    
    # æ‰“ä¹±æœ€ç»ˆç»“æœçš„é¡ºåº
    result = result.sample(frac=1, random_state=seed).reset_index(drop=True)
    
    return result, stats


def main():
    parser = argparse.ArgumentParser(
        description="ä»CSVä¸­è¿›è¡Œå‡è¡¡æŠ½æ ·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä» data.csv ä¸­æŒ‰ book_title åˆ—å‡è¡¡æŠ½å– 100 æ¡æ•°æ®
  python balanced_sample.py data.csv -n 100 -c book_title
  
  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶å’Œéšæœºç§å­
  python balanced_sample.py data.csv -n 50 -c category -o sampled.csv --seed 42
  
  # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
  python balanced_sample.py data.csv -n 100 -c type --show-stats
        """
    )
    
    parser.add_argument("input", help="è¾“å…¥CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-n", "--num", type=int, required=True, help="è¦æŠ½å–çš„æ€»æ•°é‡")
    parser.add_argument("-c", "--column", required=True, help="ç”¨äºå‡è¡¡çš„åˆ—å")
    parser.add_argument("-o", "--output", help="è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--seed", type=int, help="éšæœºç§å­")
    parser.add_argument("--show-stats", action="store_true", help="æ˜¾ç¤ºæŠ½æ ·ç»Ÿè®¡ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # è¯»å–è¾“å…¥æ–‡ä»¶
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{args.input}' ä¸å­˜åœ¨")
        return 1
    
    print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {args.input}")
    df = pd.read_csv(args.input)
    print(f"   æ€»å…± {len(df)} æ¡æ•°æ®, {len(df.columns)} åˆ—")
    
    # è¿‡æ»¤æ‰ answer_quote_text ä¸ºç©ºçš„è¡Œ
    if 'answer_quote_text' in df.columns:
        original_len = len(df)
        df = df[df['answer_quote_text'].notna() & (df['answer_quote_text'].str.strip() != '')]
        filtered_count = original_len - len(df)
        if filtered_count > 0:
            print(f"   ğŸ” è¿‡æ»¤æ‰ {filtered_count} æ¡ answer_quote_text ä¸ºç©ºçš„æ•°æ®ï¼Œå‰©ä½™ {len(df)} æ¡")
    
    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    if args.column not in df.columns:
        print(f"âŒ é”™è¯¯: åˆ— '{args.column}' ä¸å­˜åœ¨")
        print(f"   å¯ç”¨çš„åˆ—: {', '.join(df.columns)}")
        return 1
    
    # æ£€æŸ¥æŠ½æ ·æ•°é‡æ˜¯å¦åˆç†
    if args.num > len(df):
        print(f"âš ï¸  è­¦å‘Š: è¯·æ±‚æŠ½å– {args.num} æ¡ï¼Œä½†åªæœ‰ {len(df)} æ¡æ•°æ®")
        print(f"   å°†æŠ½å–å…¨éƒ¨ {len(df)} æ¡æ•°æ®")
        args.num = len(df)
    
    # æ‰§è¡Œå‡è¡¡æŠ½æ ·
    result, stats = balanced_sample(df, args.column, args.num, args.seed)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = input_path.parent / f"{input_path.stem}_sampled{input_path.suffix}"
    
    # ä¿å­˜ç»“æœ
    result.to_csv(output_path, index=False)
    print(f"\nâœ… å·²ä¿å­˜ {len(result)} æ¡æ•°æ®åˆ°: {output_path}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.show_stats:
        print(f"\nğŸ“ˆ æŠ½æ ·ç»Ÿè®¡:")
        for value, count in sorted(stats.items(), key=lambda x: str(x[0])):
            print(f"   {value}: {count} æ¡")
    
    return 0


if __name__ == "__main__":
    exit(main())

